---
title: "Introduction to Machine Learning"
subtitle: "Lab 1 Block 2"
author: "Rasmus Holm"
date: "`r Sys.Date()`"
fontsize: 10pt
geometry: margin=1in
output:
    pdf_document:
        toc: true
        number_sections: false
        fig_caption: yes
        keep_tex: yes
        includes:
            in_header: styles.sty
---

```{r global-options, echo = FALSE, eval=TRUE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
knitr::opts_chunk$set(fig.pos='H', fig.align='center')

knitr::read_chunk("../assignment1/solution.R")
knitr::read_chunk("../assignment2/solution.R")
```

\newpage

# Assignment 1
```{r, echo=FALSE, eval=TRUE}
<<assign1-init>>
```

In this assignment I have used the cube data set that contains points in a two-dimensional plane.

## 2
```{r plot12, echo=FALSE, eval=TRUE, fig.cap="Piecewise Linear Model"}
<<assign1-2>>
```

Figure \ref{fig:plot12} shows that the fit is pretty reasonable, the location of the knots are not ideal. For instance the knot at $x = 4$ should probably have been moved to around $x = 5$ for an even better fit.

It is a continuous piecewise linear function as it should be due to the constraints

\begin{equation*}
\begin{aligned}
& h_{3}(X) = (X - \xi_{1})_{+}, \\
& h_{4}(X) = (X - \xi_{2})_{+}
\end{aligned}
\end{equation*}

and it means that there are no derivatives at the knots/end points and only derivatives of order one elsewhere.

## 3
```{r plot13, echo=FALSE, eval=TRUE, fig.cap="Cubic Smooth Spline"}
<<assign1-3>>
```

The cubic smooth spline fit in figure \ref{fig:plot13} is much wigglier and seems to follow the noise in the data. However, it is a much better fit overall compared to the piecewise linear function.

I would say the cubic smooth spline fit is better than the previous one but maybe with a more thought-out placement of the knots the piecewise linear may be more appropriate. It has higher bias and therefore do not get as affected by the noise as the smooth spline which may lead to better generalization. The data also looks like three linear segments where the observations are spread evenly below/above these imaginary lines.

\newpage

# Assignment 2
```{r, echo=FALSE, eval=TRUE}
<<assign2-init>>
```

In the following exercises I have used the influenza data set that contains weekly data on the mortality and the number of laboratory-confirmed cases of influenza in Sweden.

## 1
```{r plot21, echo=FALSE, eval=TRUE, fig.cap="Influenza and mortality cases as time series between 1995 and 2004"}
<<assign2-1>>
```

From figure \ref{fig:plot21} we can see that spikes in influenza also resulted in increased mortality cases over the complete timeline. This indicates that mortality cases are positively correlated with influenza.

## 2
```{r, echo=FALSE, eval=TRUE}
<<assign2-2>>
```

In this exercise I assume $\textit{Mortality} \sim \mathcal{N}(\mu, \sigma^{2})$ so the probabilistic model becomes

\begin{equation*}
g(\mathbf{E} \left[ \textit{ Mortality } | \textit{ Year}, \textit{Week } \right]) = \alpha + \beta_{1} \textit{Year} + f(\textit{Week}),
\end{equation*}

where $\text{g}(\mu) = \mu$ is the link function and $f$ is a spline with an estimated degrees of freedom of $8.487$.

## 3
```{r plot23, echo=FALSE, eval=TRUE, fig.cap="Fitted model to the actual data."}
<<assign2-3-plot>>
```

Figure \ref{fig:plot23} shows that the generalized additive model (GAM) is a decent fit to the data. The true data is very chaotic which the model does not capture, i.e. do not overfit to the noise, but it does underfit the peaks so overall I would say the model underfits the data.

We can also see that the mortality outbreak occurs in the beginning of each year and then decreases until winter is coming again, so the mortality is positively correlated with influenza cases which in turn are increased by the colder climate in the late/early months of each year.

```{r, echo=FALSE, eval=TRUE, fig.cap="Caption."}
<<assign2-3-summary>>
```

From the model summary above we can see that the spline component is statistical significant while the intercept and year variable are not. This is not suprising given that the data is non-linear from figure \ref{fig:plot23}.

```{r spline, echo=FALSE, eval=TRUE, fig.cap="The week spline function."}
<<assign2-3-spline>>
```

The fitted \textit{week} spline function can be seen in figure \ref{fig:spline} with the pointwise standard errors included. It shows that the value is high in the early/late weeks and it is at its lowest point in the middle of the year, i.e. the summer months. This correspond to the same analysis as previously that mortality cases increase in the early/late months each year.

## 4
We know that the smoothing penalty factor, $\lambda$, and degrees of freedom for a spline have the following relationship.

\begin{equation*}
\text{df}_{\lambda} = \sum_{k = 1}^{N} \frac{1}{1 + \lambda d_{k}}
\end{equation*}

implicates that as $\lambda$ increases the degrees of freedom decreases and vice verse. Figure \ref{fig:plot24} shows how the fit changes with varying penalty factors (sp parameter) with the maximum degrees of freedom set to a fixed value of $51$ (k parameter).

```{r plot24, echo=FALSE, eval=TRUE, fig.cap="Shows how the estimation changes with varying the penalty factor of the GAM."}
<<assign2-4>>
```

As the penalty factor increases the fit becomes less flexible due to a decrease in the degrees of freedom which results in a fit that does not match the data particular well and this follows directly from the theory above. A penalty factor of 0 or 10 are decent in this case but the model is still underfitting the real underlying data which means that the model is not complex enough. The maximum degrees of freedom possible is used when the penalty factor is set to 0 and therefore indicates the result that the \textit{week} feature cannot explain the mortality completely so a better model would need to incorporate more knowledge.


```{r deviance, echo=FALSE, eval=TRUE, fig.cap="Deviance versus penalty factor."}
<<assign2-4-deviance>>
```

Figure \ref{fig:deviance} shows that as the penalty factor increases so does the estimated deviance of the model which is not desirable.

## 5
```{r plot25, echo=FALSE, eval=TRUE, fig.cap="Residuals from the GAM in exercise 2."}
<<assign2-5>>
```

The residuals are usually negative when \textit{influenza} is at 0 and large positive spikes when the \textit{influenza} is above 0 as shown in figure \ref{fig:plot25}. This indicates that the model underestimates during the early/late months and usually overestimates the other months.

## 6
In this new model I have modelled \textit{mortality} as an additive function of the spline functions of \textit{year}, \textit{week}, and \textit{influenza}.

```{r, echo=FALSE, eval=TRUE}
<<assign2-6-summary>>
```

The model summary above shows that the \textit{influenza} is statistical significant in explaining the mortality and so is the \textit{week} variable like before.

```{r plot26, echo=FALSE, eval=TRUE, fig.cap="Fitted model to the actual data."}
<<assign2-6-plot>>
```

The new model is fitting the data much better than before as shown in figure \ref{fig:plot26} and from the summary we can conclude that the \textit{week} and \textit{influenza} variables explain most of the mortality cases, roughly $84\%$ of the deviance.

\newpage

# Appendix

## Code for Assignment 1
```{r, echo=TRUE, eval=FALSE, tidy=FALSE, highlight=TRUE}
<<assign1-init>>
<<assign1-2>>
<<assign1-3>>
```

## Code for Assignment 2
```{r, echo=TRUE, eval=FALSE, tidy=FALSE, highlight=TRUE}
<<assign2-init>>
<<assign2-1>>
<<assign2-2>>

<<assign2-3-plot>>
<<assign2-3-summary>>
<<assign2-3-spline>>

<<assign2-4>>
<<assign2-4-deviance>>

<<assign2-5>>

<<assign2-6-summary>>
<<assign2-6-plot>>
```
