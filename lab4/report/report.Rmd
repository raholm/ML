---
title: "Introduction to Machine Learning"
subtitle: "Lab 4"
author: "Rasmus Holm"
date: "`r Sys.Date()`"
fontsize: 10pt
geometry: margin=1in
output:
    pdf_document:
        toc: true
        number_sections: false
        fig_caption: yes
        keep_tex: yes
        includes:
            in_header: styles.sty
---

```{r global-options, echo = FALSE, eval=TRUE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
knitr::opts_chunk$set(fig.pos='H', fig.align='center')

knitr::read_chunk("../assignment1/solution.R")
knitr::read_chunk("../assignment2/solution.R")
```

\newpage

# Assignment 1
```{r, echo=FALSE, eval=TRUE}
<<assign1-init>>
```

## 1
```{r, echo=FALSE, eval=TRUE}
<<assign1-1>>
```

The data looks like it could be modelled reasonably by a cubic spline function.

## 2
```{r, echo=FALSE, eval=TRUE, results="hide"}
<<assign1-2>>
```

Here I have modelled the data using a regression tree by letting cross-validation choose the number of leaves.

```{r 12tree, echo=FALSE, eval=TRUE, fig.cap="Regression tree fit."}
<<assign1-2-tree-plot>>
```

Figure \ref{fig:12tree} shows the resulting tree and it turned out that the optimal tree has 3 leaves.

```{r 12treefit, echo=FALSE, eval=TRUE, fig.cap="Shows the fitted values from the regression tree."}
<<assign1-2-tree-fit>>
```

The fitted values can be seen in figure \ref{fig:12treefit} and they have a decent resemblance of the original data but the model seems to be too simplistic to capture the underlying distribution the data set was generated from.


```{r 12treeresid, echo=FALSE, eval=TRUE, fig.cap="The distribution of the residuals from the regression tree."}
<<assign1-2-tree-resid>>
```

We can see from figure \ref{fig:12treeresid} that the residuals have approximately a Gaussian distribution or some form of right-tailed Gamma distribution. Since there are only 48 observations in the data set it is difficult to get a good approximation of the distribution.

## 3
```{r, echo=FALSE, eval=TRUE, warning=FALSE}
<<assign1-3>>
```

In this exercise I have used non-parametric bootstrap in order to approximate the 95\% confidence bands for the regression model.

```{r 13confbands, echo=FALSE, eval=TRUE, fig.cap="The confidence bands found by non-parametric bootstrap after 1000 samples."}
<<assign1-3-confbands>>
```

The confidence bands are quite wide in figure \ref{fig:13confbands} which indicates that the model cannot capture the data particular well since it is unsure where its mean prediction should be. The model is more certain in the middle values of the MET feature and very uncertain at low values of MET.

We can also see that the confidence bands are bumpy which I would assume have to do with the data density in our data set. Since we only have 48 observations it is not possible to have a high granularity in the confidence bands but by increasing the number of bootstrap samples it will probably become more smooth. However, it will never be completely smooth since there are simply not enough data to be able to capture the models uncertainty for all x-values.

## 4
```{r, echo=FALSE, eval=TRUE, warning=FALSE}
<<assign1-4>>
```

Here I have instead used the parametric bootstrap where I have assumed that $Y \sim \mathcal{N}(\mu_{i}, \sigma^2)$ where $\mu_{i}$ are the values in the tree leaves and $\sigma^2$ is the residual variance.

```{r 14confbands, echo=FALSE, eval=TRUE, fig.cap="The confidence and prediction bands found by parametric bootstrap after 1000 samples. The red bands are the confidence bands and the blue bands are the prediction bands."}
<<assign1-4-confbands>>
```

We can see from figure \ref{fig:14confbands} that, as expected, the prediction bands are wider than the confidence bands because not only do we consider the uncertainty of the regression model but also the uncertainty of the data itself. Compared to the previous result, the confidence bands are narrower and much more consistent over the whole range of the MET feature. The bands are also a lot smoother than previously but still pretty wide which indicates that the regression model is not very well suited for this data set. Two observations are outside the prediction bands and 5\% of 48 is approximately 2 so it is as we would expect.

## 5
Given that the residuals looked to have a Gaussian/Gamma distribution it would be more appropriate to use parametric bootstrap so we could explicitly guide the method to approximate the confidence and prediction bands.

\newpage

# Assignment 2
```{r, echo=FALSE, eval=TRUE}
<<assign2-init>>
```

In this assignment I have used the NIRspectra data set that contains near-infrared spectra and viscosity levels for a collection of diesel fuels

## 1
```{r, echo=FALSE, eval=TRUE}
<<assign2-1>>
```

```{r, echo=FALSE, eval=TRUE}
<<assign2-1-variance>>
```

```{r 21pcvar, echo=FALSE, eval=TRUE, fig.cap="Variance explained by the first 10 principal components."}
<<assign2-1-variance-plot>>
```

Figure \ref{fig:21pcvar} shows that basically all the variance can be explained by the first 5 principal components (PCs). The first two are clearly the most important and can be extracted without much loss of information, combined they explain over 99\% of the variance.

```{r 21score, echo=FALSE, eval=TRUE, fig.cap="The data projected onto the first two principal components."}
<<assign2-1-score>>
```

From figure \ref{fig:21score} there are clear outliers with very high values in the first PC. Most observations have a low value but rather spread out values in the second PC which is surprising since the first PC are supposed to explain most of the variance. However, since the scales are very different it make sense.

## 2
```{r, echo=FALSE, eval=TRUE}
<<assign2-2>>
```

```{r 22trace, echo=FALSE, eval=TRUE, fig.cap="Trace plot of the first two principal components."}
<<assign2-2-trace>>
```

From the trace plot in figure \ref{fig:22trace} we can observe that the first and second PCs are combinations of basically all the variables to different extent. The first PC has relatively high combination of all variables but slightly less of the last ones while the second PC is mostly a combination of the last ones.

## 3
```{r, echo=FALSE, eval=TRUE, warning=FALSE}
<<assign2-3>>
```

```{r 23trace, echo=FALSE, eval=TRUE, fig.cap="Traceplot of the first two independent components."}
<<assign2-3-trace>>
```

Similarly from the PC components in figure \ref{fig:22trace}, we can see that the independent components (ICs) in figure \ref{fig:23trace} have opposite shapes. The second IC is mostly a combination of the last variables while the first IC explains more information from the other variables.

```{r 23score, echo=FALSE, eval=TRUE, fig.cap="The data projected onto the first two independent components."}
<<assign2-3-score>>
```

The scores in figure \ref{fig:23score} have similar shape to that of the principal components (fig. \ref{fig:21score}) but with very different scales. Outliers can clearly be detected in the data.

## 4
```{r, echo=FALSE, eval=TRUE}
<<assign2-4>>
```

In this exercise I have used principal component regression (PCR) in order to estimate the viscosity.

```{r 24msep, echo=FALSE, eval=TRUE, fig.cap="Mean Squared Error of Prediction against number of principal components."}
<<assign2-4-MSEP>>
```

Figure \ref{fig:24msep} shows how the mean squared error changes when varying the number of PCs in PCR using cross validation. The optimal number of PCs are probably either around 7 or 17 depending on how much you value fewer features and a simpler model.

\newpage

# Appendix

## Code for Assignment 1
```{r, echo=TRUE, eval=FALSE, tidy=FALSE, highlight=TRUE}
<<assign1-init>>
<<assign1-1>>

<<assign1-2>>
<<assign1-2-tree-plot>>
<<assign1-2-tree-fit>>
<<assign1-2-tree-resid>>

<<assign1-3>>
<<assign1-3-confbands>>

<<assign1-4>>
<<assign1-4-confbands>>
```

## Code for Assignment 2
```{r, echo=TRUE, eval=FALSE, tidy=FALSE, highlight=TRUE}
<<assign2-init>>

<<assign2-1>>
<<assign2-1-variance-plot>>
<<assign2-score>>

<<assign2-2>>
<<assign2-2-trace>>

<<assign2-3>>
<<assign2-3-trace>>
<<assign2-3-score>>

<<assign2-4>>
<<assign2-4-MSEP>>
```
